{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sweetviz as sv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from phik import phik_matrix\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 0\n",
    "TEST_SIZE = 0.25\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data() -> pd.DataFrame:\n",
    "    try:\n",
    "        db_config = {\n",
    "            'user': 'praktikum_student',\n",
    "            'pwd': 'Sdf4$2;d-d30pp', \n",
    "            'host': 'rc1b-wcoijxj3yxfsf3fs.mdb.yandexcloud.net',\n",
    "            'port': 6432,\n",
    "            'db': 'data-science-vehicle-db'\n",
    "        } \n",
    "        connection_string = 'postgresql://{}:{}@{}:{}/{}'.format(\n",
    "            db_config['user'],\n",
    "            db_config['pwd'],\n",
    "            db_config['host'],\n",
    "            db_config['port'],\n",
    "            db_config['db']\n",
    "        )\n",
    "        engine = create_engine(connection_string)\n",
    "        \n",
    "        query = '''\n",
    "            SELECT\n",
    "                c.*,\n",
    "                p.party_number, p.at_fault, p.insurance_premium, p.party_sobriety, p.party_drug_physical, p.cellphone_in_use,\n",
    "                v.vehicle_type, v.vehicle_transmission, v.vehicle_age\n",
    "            FROM\n",
    "                collisions c\n",
    "            INNER JOIN\n",
    "                parties p ON c.case_id = p.case_id\n",
    "            INNER JOIN\n",
    "                vehicles v ON c.case_id = v.case_id\n",
    "            WHERE\n",
    "                c.collision_date BETWEEN '2012-01-01' AND '2012-12-31'\n",
    "                AND c.collision_damage != 'scratch'\n",
    "                AND p.party_type = 'car';\n",
    "        '''\n",
    "        data = pd.read_sql_query(query, con=engine)\n",
    "        return data\n",
    "    except Exception:\n",
    "        print(f'Error: {Exception}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()\n",
    "data.case_id = data.case_id.astype('int')\n",
    "data = data[data['distance'] < 4000.0]\n",
    "data.direction = data.direction.fillna('unknown').astype('category')\n",
    "data.intersection = data.intersection.apply(lambda x: 'Y' if x == 1. else \n",
    "                                                      'N' if x == 0 else x).fillna('unknown').astype('category')\n",
    "data.weather_1 = data.weather_1.fillna('unknown').astype('category')\n",
    "data.location_type = data.location_type.fillna('unknown').astype('category')\n",
    "data.collision_damage = data.collision_damage.astype('category')\n",
    "data.party_count = data.party_count.apply(lambda x: '5+' if x > 4 else x).apply(\n",
    "    lambda x: 'one' if x == 1 else\n",
    "              'two' if x == 2 else\n",
    "              'three' if x == 3 else\n",
    "              'four' if x == 4 else\n",
    "              'five_plus' if str(x) == '5+' else x).astype('category')\n",
    "data.primary_collision_factor = data.primary_collision_factor.fillna('unknown').astype('category')\n",
    "data.pcf_violation_category = data.pcf_violation_category.fillna('unknown').astype('category')\n",
    "data.type_of_collision = data.type_of_collision.fillna('other').astype('category')\n",
    "data.motor_vehicle_involved_with = data.motor_vehicle_involved_with.fillna('unknown').astype('category')\n",
    "data.road_surface = data.road_surface.fillna('unknown').astype('category')\n",
    "data.road_condition_1 = data.road_condition_1.fillna('other').astype('category')\n",
    "data.lighting = data.lighting.fillna('unknown').astype('category')\n",
    "data.control_device = data.control_device.fillna('unknown').astype('category')\n",
    "data.collision_date = pd.to_datetime(data.collision_date)\n",
    "data['collision_month'] = data.collision_date.dt.month\n",
    "data['collision_day'] = data.collision_date.dt.day\n",
    "data.collision_time = pd.to_datetime(data.collision_time, format='%H:%M:%S')\n",
    "data['collision_hour'] = data.collision_time.dt.hour\n",
    "data.party_number = data.party_number.apply(lambda x: '5+' if x > 4 else x).apply(\n",
    "    lambda x: 'one' if x == 1 else\n",
    "              'two' if x == 2 else\n",
    "              'three' if x == 3 else\n",
    "              'four' if x == 4 else\n",
    "              'five_plus' if str(x) == '5+' else x).astype('category')\n",
    "data.at_fault = data.at_fault.astype('category')\n",
    "data.party_sobriety = data.party_sobriety.fillna('unknown').astype('category')\n",
    "data.party_drug_physical = data.party_drug_physical.fillna('unknown').astype('category')\n",
    "data.cellphone_in_use = data.cellphone_in_use.fillna('3.0').apply(\n",
    "    lambda x: 'no' if x == 0 else\n",
    "              'yes' if x == 1 else\n",
    "              'unknown' if x == 3 else x).astype('category')\n",
    "data.vehicle_type = data.vehicle_type.astype('category')\n",
    "data.vehicle_transmission = data.vehicle_transmission.fillna('unknown').astype('category')\n",
    "data = data[data['vehicle_age'] < 161.0]\n",
    "data['insurance_premium'] = data['insurance_premium'].fillna(-1)\n",
    "data['collision_hour'] = data['collision_hour'].interpolate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = sv.analyze(data)\n",
    "# report.show_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15, 13))\n",
    "# sns.heatmap(phik_matrix(data[[\n",
    "#     'county_location',\n",
    "#     'intersection',\n",
    "#     'weather_1',\n",
    "#     'location_type',\n",
    "#     'collision_damage',\n",
    "#     'party_count',\n",
    "#     'primary_collision_factor',\n",
    "#     'pcf_violation_category',\n",
    "#     'type_of_collision',\n",
    "#     'motor_vehicle_involved_with',\n",
    "#     'road_surface',\n",
    "#     'road_condition_1',\n",
    "#     'lighting',\n",
    "#     'control_device',\n",
    "#     'party_number',\n",
    "#     'at_fault',\n",
    "#     'party_sobriety',\n",
    "#     'party_drug_physical',\n",
    "#     'cellphone_in_use',\n",
    "#     'vehicle_transmission',\n",
    "# ]], interval_cols=['distance', 'insurance_premium', 'vehicle_age', 'collision_month', 'collision_day', 'collision_hour']), annot=True, cmap='coolwarm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    'distance', \n",
    "    'insurance_premium', \n",
    "    'vehicle_age', \n",
    "    'collision_month', \n",
    "    'collision_day', \n",
    "    'collision_hour'\n",
    "]\n",
    "cat_cols = [\n",
    "    'county_location',\n",
    "    'intersection',\n",
    "    'weather_1',\n",
    "    'location_type',\n",
    "    'collision_damage',\n",
    "    'party_count',\n",
    "    'primary_collision_factor',\n",
    "    'pcf_violation_category',\n",
    "    'type_of_collision',\n",
    "    'motor_vehicle_involved_with',\n",
    "    'road_surface',\n",
    "    'road_condition_1',\n",
    "    'lighting',\n",
    "    'control_device',\n",
    "    'party_number',\n",
    "    'party_sobriety',\n",
    "    'party_drug_physical',\n",
    "    'cellphone_in_use',\n",
    "    'vehicle_transmission'\n",
    "]\n",
    "all_colls = num_cols + cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[all_colls]\n",
    "y = data.at_fault\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    "    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preporation(\n",
    "        numeric_cols: list = num_cols,\n",
    "        category_cols: list = cat_cols,\n",
    "        X_train: pd.DataFrame = X_train,\n",
    "        X_test: pd.DataFrame = X_test\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numeric_cols),\n",
    "        ('cat', OrdinalEncoder(\n",
    "            handle_unknown='use_encoded_value', \n",
    "            unknown_value=np.nan                     \n",
    "        ), category_cols)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "    X_train = pd.DataFrame(X_train_processed, columns=feature_names)\n",
    "    X_test = pd.DataFrame(X_test_processed, columns=feature_names)\n",
    "    return X_train, X_test\n",
    "\n",
    "X_train, X_test = data_preporation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.FloatTensor(X_train.values)\n",
    "X_test_torch = torch.FloatTensor(X_test.values)\n",
    "y_train_torch = torch.FloatTensor(y_train.values)\n",
    "y_test_torch = torch.FloatTensor(y_test.values)\n",
    "\n",
    "train_dataset_torch = TensorDataset(X_train_torch, y_train_torch)\n",
    "test_dataset_torch = TensorDataset(X_test_torch, y_test_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num__distance                       0\n",
      "num__insurance_premium              0\n",
      "num__vehicle_age                    0\n",
      "num__collision_month                0\n",
      "num__collision_day                  0\n",
      "num__collision_hour                 0\n",
      "cat__county_location                0\n",
      "cat__intersection                   0\n",
      "cat__weather_1                      0\n",
      "cat__location_type                  0\n",
      "cat__collision_damage               0\n",
      "cat__party_count                    0\n",
      "cat__primary_collision_factor       0\n",
      "cat__pcf_violation_category         0\n",
      "cat__type_of_collision              0\n",
      "cat__motor_vehicle_involved_with    0\n",
      "cat__road_surface                   0\n",
      "cat__road_condition_1               0\n",
      "cat__lighting                       0\n",
      "cat__control_device                 0\n",
      "cat__party_number                   0\n",
      "cat__party_sobriety                 0\n",
      "cat__party_drug_physical            0\n",
      "cat__cellphone_in_use               0\n",
      "cat__vehicle_transmission           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Написание модели pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_units, dropout_rate):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_units),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(hidden_units, hidden_units//2),\n",
    "            nn.BatchNorm1d(hidden_units//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(hidden_units//2, hidden_units//4),\n",
    "            nn.BatchNorm1d(hidden_units//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(hidden_units//4, hidden_units//8),\n",
    "            nn.BatchNorm1d(hidden_units//8),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(hidden_units//8, 1),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'hidden_units': trial.suggest_categorical('hidden_units', [256, 512, 1024, 2048]),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.1, 0.5),\n",
    "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [64, 128, 256, 512, 1024, 2048])\n",
    "    }\n",
    "\n",
    "    print(f\"\\n=== Starting Trial {trial.number} ===\")\n",
    "    print(f\"Parameters: {params}\")\n",
    "\n",
    "    train_loader = DataLoader(train_dataset_torch,\n",
    "                              batch_size=params['batch_size'],\n",
    "                              shuffle=True)\n",
    "    \n",
    "    net = Net(\n",
    "        input_size=X_train.shape[1],\n",
    "        hidden_units=params['hidden_units'],\n",
    "        dropout_rate=params['dropout_rate']\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=params['lr'])\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best_f1 = 0\n",
    "    patience = 5\n",
    "    no_improve = 0\n",
    "    num_epoch = 2000\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        net.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            train_preds = net(inputs)\n",
    "            train_loss = loss_fn(train_preds, labels.unsqueeze(1))\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch % 5 == 0 or epoch == num_epoch -1:\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                test_inputs, test_labels = X_test_torch.to(device), y_test_torch.to(device)\n",
    "                outputs = net(test_inputs)\n",
    "                test_preds = (outputs > 0.5).float()\n",
    "                test_f1 = f1_score(test_labels.cpu(), test_preds.cpu())\n",
    "                \n",
    "                if test_f1 > best_f1:\n",
    "                    best_f1 = test_f1\n",
    "                    no_improve = 0\n",
    "                    best_epoch = epoch\n",
    "                else:\n",
    "                    no_improve += 1\n",
    "\n",
    "                print(f\"Trial {trial.number} | Epoch {epoch:3d} | \"\n",
    "                      f\"Val F1: {test_f1:.4f} | Best F1: {best_f1:.4f} @ Epoch {best_epoch}\")\n",
    "\n",
    "                if no_improve >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "\n",
    "            trial.report(test_f1, epoch)\n",
    "            if trial.should_prune():\n",
    "                print(f\"Pruned trial {trial.number} at epoch {epoch}\")\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "    print(f\"=== Completed Trial {trial.number} | Best F1: {best_f1:.4f} ===\")\n",
    "    return best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 13:44:26,171] A new study created in memory with name: no-name-509ccd0c-7bc9-4c0c-8114-f9b9180c2182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Trial 0 ===\n",
      "Parameters: {'hidden_units': 256, 'dropout_rate': 0.1534555981183385, 'lr': 0.00019855387735360697, 'batch_size': 128}\n",
      "Trial 0 | Epoch   0 | Val F1: 0.8717 | Best F1: 0.8717 @ Epoch 0\n",
      "Trial 0 | Epoch   5 | Val F1: 0.9038 | Best F1: 0.9038 @ Epoch 5\n",
      "Trial 0 | Epoch  10 | Val F1: 0.9051 | Best F1: 0.9051 @ Epoch 10\n",
      "Trial 0 | Epoch  15 | Val F1: 0.9038 | Best F1: 0.9051 @ Epoch 10\n",
      "Trial 0 | Epoch  20 | Val F1: 0.9045 | Best F1: 0.9051 @ Epoch 10\n",
      "Trial 0 | Epoch  25 | Val F1: 0.9012 | Best F1: 0.9051 @ Epoch 10\n",
      "Trial 0 | Epoch  30 | Val F1: 0.9059 | Best F1: 0.9059 @ Epoch 30\n",
      "Trial 0 | Epoch  35 | Val F1: 0.9031 | Best F1: 0.9059 @ Epoch 30\n",
      "Trial 0 | Epoch  40 | Val F1: 0.9054 | Best F1: 0.9059 @ Epoch 30\n",
      "Trial 0 | Epoch  45 | Val F1: 0.9049 | Best F1: 0.9059 @ Epoch 30\n",
      "Trial 0 | Epoch  50 | Val F1: 0.9027 | Best F1: 0.9059 @ Epoch 30\n",
      "Trial 0 | Epoch  55 | Val F1: 0.9061 | Best F1: 0.9061 @ Epoch 55\n",
      "Trial 0 | Epoch  60 | Val F1: 0.9048 | Best F1: 0.9061 @ Epoch 55\n",
      "Trial 0 | Epoch  65 | Val F1: 0.9023 | Best F1: 0.9061 @ Epoch 55\n",
      "Trial 0 | Epoch  70 | Val F1: 0.9037 | Best F1: 0.9061 @ Epoch 55\n",
      "Trial 0 | Epoch  75 | Val F1: 0.9044 | Best F1: 0.9061 @ Epoch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 13:46:20,616] Trial 0 finished with value: 0.9061100510144476 and parameters: {'hidden_units': 256, 'dropout_rate': 0.1534555981183385, 'lr': 0.00019855387735360697, 'batch_size': 128}. Best is trial 0 with value: 0.9061100510144476.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 | Epoch  80 | Val F1: 0.9050 | Best F1: 0.9061 @ Epoch 55\n",
      "Early stopping at epoch 80\n",
      "=== Completed Trial 0 | Best F1: 0.9061 ===\n",
      "\n",
      "=== Starting Trial 1 ===\n",
      "Parameters: {'hidden_units': 2048, 'dropout_rate': 0.41354191811329744, 'lr': 0.0017761817159793988, 'batch_size': 512}\n",
      "Trial 1 | Epoch   0 | Val F1: 0.8875 | Best F1: 0.8875 @ Epoch 0\n",
      "Trial 1 | Epoch   5 | Val F1: 0.9051 | Best F1: 0.9051 @ Epoch 5\n",
      "Trial 1 | Epoch  10 | Val F1: 0.9060 | Best F1: 0.9060 @ Epoch 10\n",
      "Trial 1 | Epoch  15 | Val F1: 0.9060 | Best F1: 0.9060 @ Epoch 15\n",
      "Trial 1 | Epoch  20 | Val F1: 0.9022 | Best F1: 0.9060 @ Epoch 15\n",
      "Trial 1 | Epoch  25 | Val F1: 0.9056 | Best F1: 0.9060 @ Epoch 15\n",
      "Trial 1 | Epoch  30 | Val F1: 0.9084 | Best F1: 0.9084 @ Epoch 30\n",
      "Trial 1 | Epoch  35 | Val F1: 0.9073 | Best F1: 0.9084 @ Epoch 30\n",
      "Trial 1 | Epoch  40 | Val F1: 0.9073 | Best F1: 0.9084 @ Epoch 30\n",
      "Trial 1 | Epoch  45 | Val F1: 0.9076 | Best F1: 0.9084 @ Epoch 30\n",
      "Trial 1 | Epoch  50 | Val F1: 0.9030 | Best F1: 0.9084 @ Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 13:51:10,064] Trial 1 finished with value: 0.9083761482173439 and parameters: {'hidden_units': 2048, 'dropout_rate': 0.41354191811329744, 'lr': 0.0017761817159793988, 'batch_size': 512}. Best is trial 1 with value: 0.9083761482173439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 | Epoch  55 | Val F1: 0.9042 | Best F1: 0.9084 @ Epoch 30\n",
      "Early stopping at epoch 55\n",
      "=== Completed Trial 1 | Best F1: 0.9084 ===\n",
      "\n",
      "=== Starting Trial 2 ===\n",
      "Parameters: {'hidden_units': 256, 'dropout_rate': 0.4054349899798625, 'lr': 0.004748286329707304, 'batch_size': 64}\n",
      "Trial 2 | Epoch   0 | Val F1: 0.9028 | Best F1: 0.9028 @ Epoch 0\n",
      "Trial 2 | Epoch   5 | Val F1: 0.9046 | Best F1: 0.9046 @ Epoch 5\n",
      "Trial 2 | Epoch  10 | Val F1: 0.9048 | Best F1: 0.9048 @ Epoch 10\n",
      "Trial 2 | Epoch  15 | Val F1: 0.9016 | Best F1: 0.9048 @ Epoch 10\n",
      "Trial 2 | Epoch  20 | Val F1: 0.9048 | Best F1: 0.9048 @ Epoch 20\n",
      "Trial 2 | Epoch  25 | Val F1: 0.9053 | Best F1: 0.9053 @ Epoch 25\n",
      "Trial 2 | Epoch  30 | Val F1: 0.9066 | Best F1: 0.9066 @ Epoch 30\n",
      "Trial 2 | Epoch  35 | Val F1: 0.9029 | Best F1: 0.9066 @ Epoch 30\n",
      "Trial 2 | Epoch  40 | Val F1: 0.9071 | Best F1: 0.9071 @ Epoch 40\n",
      "Trial 2 | Epoch  45 | Val F1: 0.9067 | Best F1: 0.9071 @ Epoch 40\n",
      "Trial 2 | Epoch  50 | Val F1: 0.9067 | Best F1: 0.9071 @ Epoch 40\n",
      "Trial 2 | Epoch  55 | Val F1: 0.9069 | Best F1: 0.9071 @ Epoch 40\n",
      "Trial 2 | Epoch  60 | Val F1: 0.9079 | Best F1: 0.9079 @ Epoch 60\n",
      "Trial 2 | Epoch  65 | Val F1: 0.9052 | Best F1: 0.9079 @ Epoch 60\n",
      "Trial 2 | Epoch  70 | Val F1: 0.9087 | Best F1: 0.9087 @ Epoch 70\n",
      "Trial 2 | Epoch  75 | Val F1: 0.9024 | Best F1: 0.9087 @ Epoch 70\n",
      "Trial 2 | Epoch  80 | Val F1: 0.9050 | Best F1: 0.9087 @ Epoch 70\n",
      "Trial 2 | Epoch  85 | Val F1: 0.9075 | Best F1: 0.9087 @ Epoch 70\n",
      "Trial 2 | Epoch  90 | Val F1: 0.9066 | Best F1: 0.9087 @ Epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 13:55:04,899] Trial 2 finished with value: 0.9087185036327099 and parameters: {'hidden_units': 256, 'dropout_rate': 0.4054349899798625, 'lr': 0.004748286329707304, 'batch_size': 64}. Best is trial 2 with value: 0.9087185036327099.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 | Epoch  95 | Val F1: 0.9048 | Best F1: 0.9087 @ Epoch 70\n",
      "Early stopping at epoch 95\n",
      "=== Completed Trial 2 | Best F1: 0.9087 ===\n",
      "\n",
      "=== Starting Trial 3 ===\n",
      "Parameters: {'hidden_units': 512, 'dropout_rate': 0.29459150625105446, 'lr': 0.0007470485226158362, 'batch_size': 256}\n",
      "Trial 3 | Epoch   0 | Val F1: 0.9010 | Best F1: 0.9010 @ Epoch 0\n",
      "Trial 3 | Epoch   5 | Val F1: 0.9044 | Best F1: 0.9044 @ Epoch 5\n",
      "Trial 3 | Epoch  10 | Val F1: 0.9044 | Best F1: 0.9044 @ Epoch 5\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(f'best params: {study.best_params}')\n",
    "print(f'best f1: {study.best_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
